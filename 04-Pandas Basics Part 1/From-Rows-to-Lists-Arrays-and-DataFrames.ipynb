{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Rows to Lists, Arrays, and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Over Rows to Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have learned how to iterate through the rows of a file in order to process each row, one at a time.  It has its limitations.  In this session we compare working with iteration over rows, to two alternatives: generating lists from the rows, and generating arrays using Numpy.  We close with an introduction to the pandas package, which we will begin using extensively.\n",
    "\n",
    "But first, let's ceate and then load a simple cvs file with one column, containing 50 random numbers between 0 and 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task is to calculate a mean value of these numbers.  How can we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('random.csv', 'r') as csvfile:\n",
    "    i = 0\n",
    "    cumsum = 0\n",
    "    itemreader = csv.reader(csvfile)\n",
    "    for row in itemreader:\n",
    "        i = i+1\n",
    "        cumsum = cumsum+float(row[0])\n",
    "    mean = cumsum/i\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about computing the min and max values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('random.csv', 'r') as csvfile:\n",
    "    i = 0\n",
    "    cumsum = 0\n",
    "    min = 1\n",
    "    max = 0\n",
    "    itemreader = csv.reader(csvfile)\n",
    "    for row in itemreader:\n",
    "        i = i+1\n",
    "        cumsum = cumsum+float(row[0])\n",
    "        if float(row[0])>max:\n",
    "            max = float(row[0])\n",
    "        if float(row[0])<min:\n",
    "            min = float(row[0])\n",
    "    mean = cumsum/i\n",
    "    print(mean, min, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we need to compute the median of these numbers.  Remember that a median is the value for which half of the observations are less and half are greater.  Any suggestions on how to code this using our iteration approach, and without resorting to creating a list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Documentation\n",
    "\n",
    "Often we forget how to do something.  In that case, the python docs are our friend.  They can be found here: https://docs.python.org/3.5/\n",
    "\n",
    "In particular, note the language reference and the library reference.  Let's stop and take a look at each.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lists to Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things that are hard in the row iteration approach above, become easier if we can keep all of the values in one object, like a list.\n",
    "\n",
    "Let's revisit the problems above, by assembling the values from each row into a single list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('random.csv', 'r') as csvfile:\n",
    "    x = []\n",
    "    itemreader = csv.reader(csvfile)\n",
    "    for row in itemreader:\n",
    "        x.append(float(row[0]))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is now a single list object with all the values in the file, whereas initially we just had each row producing one list with one element in it (from one row), and then printing that, before recreating it with the value from the next row.  The iteration approach kept only one row at a time, and we could not easily do calculations like a median.\n",
    "\n",
    "Using the list (x), we should now have an easier time with mean and median calculations, using list methods like sum and len, and sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = sum(x)/len(x)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve the median problem by sorting the list, and getting the value that is halfway through the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.sort()\n",
    "median = x[int(len(x)/2)]\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also simple to get the min and max, using built-in list methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min = x[0]\n",
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max = x[-1]\n",
    "max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this is progress.  Can we now do other math on the data, like multiply each value by 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = x*5\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not what we wanted. That just concatenated 5 copies of the list together!\n",
    "\n",
    "Let's take a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for item in range(len(x)):\n",
    "    y.append(x[item]*5)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this is a big improvement over the iteration over rows approach, but it is still a bit tedious.\n",
    "\n",
    "## Introducing Numpy\n",
    "\n",
    "Now let's look at the use of arrays, the basic data structure added by Numpy, a library that creates, manipultates, and analyzes n-dimensional array objects, or ndarrays.  We will refer to this datatype as array for short.\n",
    "\n",
    "When we're working with a library, it is nice to keep the documentation handy.  We can find the Numpy docs here: http://www.numpy.org/.  If you're unfamiliar with a new package, you might want to start from the tutorial to cover the basics.  \n",
    "\n",
    "Arrays can be created from any sequence-like object, such as a list of integers or floats, for example.  We start by creating one from a list of floats.  \n",
    "\n",
    "First, we have to import Numpy and will assign it a shorter name of np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data1 = [3.2, 4.5, 8.0, 9.9]\n",
    "arr1 = np.array(data1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if we pass a nested list of equal-length lists, we create a two-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2 = [[1.1, 2.2 ,3.3], [1.2, 2.3, 3.4]]\n",
    "arr2 = np.array(data2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see its type, number of dimensions, size (number of elements), and shape (length of each dimension) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data type of the contents of an array, or 'cast' it to a specified data type, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr3 = arr2.astype(np.int8)\n",
    "arr3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type for the elements in an array are required to be the same.  Among other types, they can be int8, int16, int32, int64, float16, float32, float64, bool. They can also be strings of fixed length, but Numpy is mostly used for arrays of numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the range method to generate a range of integers?  We can use an analogous method called arange in Numpy to create a multi-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.arange(15).reshape(3,5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we load the same csv file with random numbers that we loaded earlier, with a built-in Numpy method, genfromtext.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.genfromtxt('random.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy Arrays are objects of type ndarray, often just called arrays. They are a special data type that support fast, vectorized calculations.  Numpy calculations are actually computed in low-level C code behind the scenes, avoiding the need for iterative loops in Python, which are well known to be very slow compared to compiled languages like C, C++ or Fortran.\n",
    "\n",
    "Let's have a look at some of the built-in methods to explore Numpy arrays.\n",
    "\n",
    "First, instead of len, we have a size method that tells us how many elements are in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can explore the shape of an array.  If it is a single column, it shows as (length,).  If it is a single row, it shows up as (,length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of mathematical methods are readily built in to Numpy.  Here are a few for mean, standard deviation, variance, median, min, max, sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.var(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much easier than coding for loops and counters, don't you think?  And a lot faster on large datasets, too.\n",
    "\n",
    "Numpy also integrates very well with Matplotlib to generate charts.  Let's look at a sorted list of the elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.sort(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution above doesn't look very random, does it?  It seems to be intended as a uniform distribution from 0 to 1, but has a disproportionate samping from above 0.8.  Let's try generating larger samples and see if it looks more uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.random.uniform(0,1,50)\n",
    "plt.hist(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.random.randn(50)\n",
    "plt.hist(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency and productivity of coding using arrays becomes even more obvious when we consider calculations like an element by element calculation -- multiplying each element by 5, for example.  No loops needed when the calculations are vectorized.  If we say, a*5 and a is an array, Numpy will perform an element by element multiplication, using fast C code to do the math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = a*5\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, multiplying two arrays together produces an element by element multiplication, in this case, instead of each element of a being multiplied by a constant (5), it is being multiplied by the corresponding value (same index position) in array b.  In other words, the first element of each array get multiplied together, the second element of each array, the third, and so on.\n",
    "\n",
    "This works as long as the arrays are of the same length, or if one is an even multiple of the other, in which case the shorter one gets repeated to make the lengths match.  That process is called broadcasting, and it is how we were able to multiply a initially by a constant. The constant was broadcast to the length of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = a*b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Advanced Uses of Numpy\n",
    "\n",
    "Numpy is a very powerful libary for mathematical and scientific computing, well beyond the limited functionality above.  It forms the foundation for Scipy, a large libray for scientific computing, and many other numeric libraries, including Pandas, which we will get to shortly.\n",
    "\n",
    "But first, a glimpse of some more advanced uses of numpy.  To get a sense of the types of things Numpy can do, we can check out the list of Numpy functions by category from their docs.  Those are here: https://docs.scipy.org/doc/numpy/reference/routines.html.  Let's take a look...\n",
    "\n",
    "Now let's look at two examples.  \n",
    "\n",
    "#### Linear Algebra\n",
    "\n",
    "You noticed that when we did array calculations in Numpy it was elementwise?  Those of you who have done any linear algebra and worked with matrix (arra) libraries might be perplexed that standard matrix operations do not result from a * b for example.  Not to worry.  Numpy can do linear algebra quite well - it just uses separate syntax for it.\n",
    "\n",
    "For example, a matrix multiplication is called a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "c = np.dot(d,d)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.transpose(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is way more to Numpy than we have covered here but if you need to do serious number crunching and advanced computation in Python, you will generally find Numpy to be a core part of the solution.  \n",
    "\n",
    "#### Generating Fractals\n",
    "\n",
    "Here is a fun example of using Numpy to generate a Mandlebrot set from a Scipy tutorial (don't ask me to explain it).  If you get curious about the theory and math behind it, Wikipedia has a good page on it. https://en.wikipedia.org/wiki/Mandelbrot_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def mandelbrot( h,w, maxit=20 ):\n",
    "    \"\"\"Returns an image of the Mandelbrot fractal of size (h,w).\"\"\"\n",
    "\n",
    "    y,x = np.ogrid[ -1.4:1.4:h*1j, -2:0.8:w*1j ]\n",
    "    c = x+y*1j\n",
    "    z = c\n",
    "    divtime = maxit + np.zeros(z.shape, dtype=int)\n",
    "\n",
    "    for i in range(maxit):\n",
    "        z = z**2 + c\n",
    "        diverge = z*np.conj(z) > 2**2            # who is diverging\n",
    "        div_now = diverge & (divtime==maxit)  # who is diverging now\n",
    "        divtime[div_now] = i                  # note when\n",
    "        z[diverge] = 2                        # avoid diverging too much\n",
    "\n",
    "    return divtime\n",
    "\n",
    "plt.imshow(mandelbrot(400,400))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have moved from processing file with iterators over rows, to lists with iterators, to using Numpy arrays to do vectorized operations that are much faster and are also less complex to read, understand and to code. We moved from operating on one item in a list at a time, to operating on a whole array at one time. Now we want to be able to move to handling the whole table of data at once.\n",
    "\n",
    "One of the problems we did not attempt to deal with using arrays, or lists, was how to keep rows of data together so that if we skip a missing value in one variable like price, it does not cause the other variables to be mis-aligned due to changes in the length of the array or list for one entry. This is one of many things that the pandas library does for us.\n",
    "We skip forward a bit to Chapter 6 in Python for Data Analysis in order to learn how to load our data using pandas. \n",
    "\n",
    "We also want to keep the Pandas docs handy here: http://pandas.pydata.org/\n",
    "\n",
    "Here is how we start with loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ca_tracts_pop_cleaned.csv')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things that have happened here.\n",
    "\n",
    "1. The pd.read_csv has enough built-in smarts to read the first row of the file, get the variable names from it.\n",
    "1. It then read all rows in the file, and used them to create a pandas DataFrame, which is like a set of Numpy arrays we can treat as a table.\n",
    "1. It created an automatic unique index, beginning with zero.\n",
    "1. It inferred the type of each variable from the data.  All were interpreted as strings, except the index that pandas created automatically.\n",
    "\n",
    "Let's explore this pandas DataFrame to learn some of its features.  Note that a pandas Series is like one column of this DataFrame, coupled with its own index column.  So the main difference between a Series and a DataFrame is that the latter has multiple columns. Columns can be of different data types, but within a column, must be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select subsets of the rows by indexing, and select specific columns by their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Population'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get all of our statistics on the Population column in one short command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Population'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get these values 'a la carte'.  You might recognize that these are essentially Numpy functions, but that in pandas we can now deal with multiple data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Population'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Population'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Population'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do some plotting of the data without much effort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.hist(column='Population', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use string operations we have already learned, and apply those to columns that are of type string.  The syntax is a bit different when used with pandas DataFrames.  Here, we create a State column and add it to df by splitting geodisplay and getting its third element.  Note that these string methods are reviewed in Pandas forData Analysis pages 206-206.  More advanced regex methods and other vectorized string methods are covered in pages 207-212."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['State'] = df['geodisplay'].str.split(',').str[2]\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a Tract column with just the tract number, and remove the 'Census Tract ' from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Tract']=df['geodisplay'].str.split(',').str[0].str.strip('Census Tract ')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way to do the last step, using replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Tract']=df['geodisplay'].str.split(',').str[0].str.replace('Census Tract ', '')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
